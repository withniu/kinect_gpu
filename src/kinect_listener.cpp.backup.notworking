#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <message_filters/synchronizer.h>
#include <message_filters/sync_policies/approximate_time.h>
#include <sensor_clouds/image_encodings.h>
#include <cv_bridge/cv_bridge.h>

#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/features2d/features2d.hpp>
#include <opencv2/imgproc/imgproc.hpp>

#include <pcl_ros/point_cloud.h>
#include <pcl/point_types.h>


#define USE_IMAGE_TRANSPORT_SUBSCRIBER_FILTER 1
#define DRAW 0

#if USE_IMAGE_TRANSPORT_SUBSCRIBER_FILTER
#  include <image_transport/subscriber_filter.h>
#else
#  include <sensor_clouds/Image.h>
#  include <message_filters/subscriber.h>
#endif

const float fx = 525.0;
const float fy = 525.0;
const float cx = 319.5;
const float cy = 239.5;


class KinectListener {
public:
	KinectListener() :
		it_(nh_),
	    	rgb_image_sub_( it_, "/camera/rgb/image_color", 1 ),
		depth_image_sub_( it_, "/camera/depth/image", 1 ),
		sync( MySyncPolicy( 10 ), rgb_image_sub_, depth_image_sub_ ) 
		{
			pub_ = nh_.advertise<pcl::PointCloud<pcl::PointXYZRGB> > ("keypoints3d", 1);
			
			index_ = 0;
			time_ = ros::Time::now();
			img1_ = cv::Mat::ones(480,640,CV_8UC3);

#if DRAW
			cv::namedWindow("RGB");			
			cv::namedWindow("Depth");
			cv::namedWindow("Feature");
			cv::namedWindow("Matches");				
#endif
			sync.registerCallback( boost::bind( &KinectListener::callback, this, _1, _2 ) );
			
		}

	void callback(const sensor_clouds::ImageConstPtr& rgb_cloud,
				  const sensor_clouds::ImageConstPtr& depth_cloud) {
		ROS_INFO("Callback in");
		ros::Time begin,end;
		begin = ros::Time::now();

		cv_bridge::CvImagePtr cv_rgb_ptr;	// cv_bridge for rgb image
		cv_bridge::CvImagePtr cv_depth_ptr;	// cv_bridge for depth image

		try
		{
			cv_rgb_ptr = cv_bridge::toCvCopy(rgb_cloud, sensor_clouds::image_encodings::BGR8);
			cv_depth_ptr = cv_bridge::toCvCopy(depth_cloud);		
		}
		catch (cv_bridge::Exception& e)
		{
			ROS_ERROR("cv_bridge exception: %s", e.what());
			return;
		}

		cv::SurfFeatureDetector detector(400);	
		cv::BruteForceMatcher<cv::L2<float> > matcher;
		cv::vector<cv::DMatch> matches;
		cv::SurfDescriptorExtractor extractor;
		cv::Mat img_matches;
		if (index_ % 2) {
			img1_ = cv_rgb_ptr->image;
			detector.detect(img1_, keypoints1_);
			extractor.compute(img1_, keypoints1_, descriptors1_);
			matcher.match(descriptors2_, descriptors1_, matches);
#if DRAW
			cv::drawKeypoints(img1_,keypoints1_,img1_features_);
			cv::imshow("Feature", img1_features_);
			cv::drawMatches(img2_, keypoints2_, img1_, keypoints1_, matches, img_matches);
#endif
		} else {
			img2_ = cv_rgb_ptr->image;
			detector.detect(img2_, keypoints2_);
			extractor.compute(img2_, keypoints2_, descriptors2_);
			matcher.match(descriptors1_, descriptors2_, matches);
#if DRAW			
			cv::drawKeypoints(img2_,keypoints2_,img2_features_);
			cv::imshow("Feature", img2_features_);			
			cv::drawMatches(img1_, keypoints1_, img2_, keypoints2_, matches, img_matches);
#endif		
		}

		
		// Calculate 3D features
		cloud_.clear();
		cloud_.header.frame_id = "some_tf_frame";
		cloud_.height = 1;
		cloud_.width = matches.size();
			
//		uint8_t r(255), g(15), b(15);
		pcl::PointXYZRGB point;		
		for (unsigned int i = 0;i < matches.size();i++) {							
			unsigned int x = keypoints1_[matches[i].queryIdx].pt.x;
			unsigned int y = keypoints1_[matches[i].queryIdx].pt.y;
			float z = cv_depth_ptr->image.at<float>(x,y);
			point.x = 1.0 / fx * (x - cx) * z;
			point.y = 1.0 / fy * (y - cy) * z;
			point.z = z;
//			uint32_t rgb = (static_cast<uint32_t>(r) << 16 |
  //            				static_cast<uint32_t>(g) << 8 | static_cast<uint32_t>(b));
    //  			point.rgb = *reinterpret_cast<float*>(&rgb);
	//		cloud_.push_back (point);		
		}

		pub_.publish(cloud_);
		ROS_INFO("Published");

#if DRAW
		cv::imshow("Matches", img_matches);
		cv::imshow("RGB", cv_rgb_ptr->image);
		cv::imshow("Depth", cv_depth_ptr->image);
		cv::waitKey(3);
#endif
		index_++;
		
//		ros::Duration(1.0).sleep();

		end = ros::Time::now();
		ros::Time time_now = ros::Time::now();
		ROS_INFO("%fs, %.2fHz",end.toSec() - begin.toSec(),1 / (time_now.toSec() - time_.toSec()));
		time_ = time_now;
  }

private:



	ros::NodeHandle nh_;
	image_transport::ImageTransport it_;
	ros::Publisher pub_;
	pcl::PointCloud<pcl::PointXYZRGB> cloud_;
	
	cv::Mat img1_,img2_;
	cv::Mat img1_features_,img2_features_;
	cv::vector<cv::KeyPoint> keypoints1_, keypoints2_;
	cv::Mat descriptors1_, descriptors2_;
	cv::vector<cv::Point3f> keypoints3d1_,keypoints3d2_;
	
	int index_;		// Count for callback to switch ping-pong
	ros::Time time_;	// Timing for callback
	
	typedef image_transport::SubscriberFilter ImageSubscriber;
	ImageSubscriber rgb_image_sub_;
	ImageSubscriber depth_image_sub_;
	typedef message_filters::sync_policies::ApproximateTime<
	sensor_clouds::Image, sensor_clouds::Image
	> MySyncPolicy;
	message_filters::Synchronizer< MySyncPolicy > sync;
};




int main(int argc, char** argv) {
  ros::init( argc, argv, "my_node" );
  KinectListener mc;

  while( ros::ok() ){
    ros::spin();
  }

  return EXIT_SUCCESS;
}
 
